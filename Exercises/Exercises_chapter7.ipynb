{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Load the MNIST data and split it into a training set, a validation set, and a test set (e.g., use 50k instances for training, 10k for validation and 10k for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "mnist.target = mnist.target.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(mnist.data, mnist.target, test_size=10000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=10000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (50000, 784)\n",
      "X_val:  (10000, 784)\n",
      "X_test:  (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"X_val: \",X_val.shape)\n",
    "print(\"X_test: \",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Train various classifiers, such as Random Forest Classifiers, an Extra-Trees and an SVM\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the classifiers\n",
    "random_forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "extra_trees_clf = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "svm_clf = LinearSVC(max_iter=100, tol=20, random_state=42)\n",
    "mlp_clf = MLPClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the  RandomForestClassifier(random_state=42)\n",
      "Training the  ExtraTreesClassifier(random_state=42)\n",
      "Training the  LinearSVC(max_iter=100, random_state=42, tol=20)\n",
      "Training the  MLPClassifier(random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# Training the models\n",
    "estimators = [random_forest_clf, extra_trees_clf, svm_clf, mlp_clf]\n",
    "for estimator in estimators:\n",
    "    print(\"Training the \",estimator)\n",
    "    estimator.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for  RandomForestClassifier(random_state=42) was  0.9692\n",
      "Score for  ExtraTreesClassifier(random_state=42) was  0.9715\n",
      "Score for  LinearSVC(max_iter=100, random_state=42, tol=20) was  0.859\n",
      "Score for  MLPClassifier(random_state=42) was  0.9663\n"
     ]
    }
   ],
   "source": [
    "for estimator in estimators:\n",
    "    print(\"Score for \", estimator, \"was \", estimator.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The SVM classifier is outperformed by the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the classifiers in a voting classifier which outperforms all of them in the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_estimators = [\n",
    "    (\"random_forest_clf\", random_forest_clf),\n",
    "    (\"extra_trees_clf\", extra_trees_clf),\n",
    "    (\"svm_clf\", svm_clf),\n",
    "    (\"mlp_clf\", mlp_clf),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(named_estimators) ## Declare the voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('random_forest_clf',\n",
       "                              RandomForestClassifier(random_state=42)),\n",
       "                             ('extra_trees_clf',\n",
       "                              ExtraTreesClassifier(random_state=42)),\n",
       "                             ('svm_clf',\n",
       "                              LinearSVC(max_iter=100, random_state=42, tol=20)),\n",
       "                             ('mlp_clf', MLPClassifier(random_state=42))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(X_train, y_train) ## Fit the voting classifier  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9713"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.score(X_val, y_val)  ## Get the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for  RandomForestClassifier(random_state=42) was  0.9692\n",
      "Score for  ExtraTreesClassifier(random_state=42) was  0.9715\n",
      "Score for  LinearSVC(max_iter=100, random_state=42, tol=20) was  0.859\n",
      "Score for  MLPClassifier(random_state=42) was  0.9663\n",
      "Score for the voting classifier:  0.9713\n"
     ]
    }
   ],
   "source": [
    "# Compare the scores\n",
    "for estimator in estimators:\n",
    "    print(\"Score for \", estimator, \"was \", estimator.score(X_val,y_val))\n",
    "print(\"Score for the voting classifier: \",voting_clf.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The voting classifier does not outperform the best classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove the SVM for the voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('random_forest_clf',\n",
       "                              RandomForestClassifier(random_state=42)),\n",
       "                             ('extra_trees_clf',\n",
       "                              ExtraTreesClassifier(random_state=42)),\n",
       "                             ('svm_clf', None),\n",
       "                             ('mlp_clf', MLPClassifier(random_state=42))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.set_params(svm_clf=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('random_forest_clf', RandomForestClassifier(random_state=42)),\n",
       " ('extra_trees_clf', ExtraTreesClassifier(random_state=42)),\n",
       " ('svm_clf', None),\n",
       " ('mlp_clf', MLPClassifier(random_state=42))]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RandomForestClassifier(random_state=42),\n",
       " ExtraTreesClassifier(random_state=42),\n",
       " LinearSVC(max_iter=100, random_state=42, tol=20),\n",
       " MLPClassifier(random_state=42)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Does not update the trained estimators\n",
    "voting_clf.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the SVM classifier\n",
    "del voting_clf.estimators_[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9742"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain the score\n",
    "voting_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The SVM decreases the performance of the voting classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use a soft voting classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf.voting = \"soft\"  # Not necessary to retrain the classifier, just set the voting parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain the score\n",
    "voting_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hard voting classifier have a better performance than the soft voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9706"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.voting = \"hard\"\n",
    "voting_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9645, 0.9691, 0.9636]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each classifier\n",
    "[estimator.score(X_test, y_test) for estimator in voting_clf.estimators_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to see that the voting classifier outperforms all of its classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Run the individual classifiers from the previous exercise to make predictions on the validation set, and create a new training set with the resulting predictions: each training instance is a vector containing the set of predictions from all your classifiers for an image, and the target is the image's class. Train a classifier on this new training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 4)\n",
      "0 RandomForestClassifier(random_state=42)\n",
      "1 ExtraTreesClassifier(random_state=42)\n",
      "2 LinearSVC(max_iter=100, random_state=42, tol=20)\n",
      "3 MLPClassifier(random_state=42)\n"
     ]
    }
   ],
   "source": [
    "X_val_predictions = np.empty((len(X_val), len(estimators)), dtype=np.float32)\n",
    "print(X_val_predictions.shape)\n",
    "\n",
    "# Run the individual classifiers \n",
    "for index, estimator in enumerate(estimators):\n",
    "    print(index,estimator)\n",
    "    # Make the predicitons on the validation set and create a vector containing the set of predictions from all classifiers\n",
    "    X_val_predictions[:, index] = estimator.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 5., 5., 5.],\n",
       "       [8., 8., 8., 8.],\n",
       "       [2., 2., 3., 2.],\n",
       "       ...,\n",
       "       [7., 7., 7., 7.],\n",
       "       [6., 6., 6., 6.],\n",
       "       [7., 7., 7., 7.]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200, oob_score=True, random_state=42)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_forest_blender = RandomForestClassifier(n_estimators=200, oob_score=True, random_state=42)\n",
    "rnd_forest_blender.fit(X_val_predictions, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9677"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_forest_blender.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blender can be used with MLPClassifiers, as example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Evaluate the ensemble on the test set. For each image in the test set, make predictions with all your classifiers, then feed the predictions to the blender to get ensemble's predictions. How does it compare to the voting classifier your trained earlier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_predictions = np.empty((len(X_test), len(estimators)), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 RandomForestClassifier(random_state=42)\n",
      "1 ExtraTreesClassifier(random_state=42)\n",
      "2 LinearSVC(max_iter=100, random_state=42, tol=20)\n",
      "3 MLPClassifier(random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# Run the individual classifiers \n",
    "for index, estimator in enumerate(estimators):\n",
    "    print(index,estimator)\n",
    "    # Make the predicitons on the validation set and create a vector containing the set of predictions from all classifiers\n",
    "    X_test_predictions[:, index] = estimator.predict(X_test) ## Predict on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the prediction\n",
    "y_pred = rnd_forest_blender.predict(X_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9827"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This stacking ensemble does not perform as well as the voting classifier we trained earlier, it's not quite as good as the best individual classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
