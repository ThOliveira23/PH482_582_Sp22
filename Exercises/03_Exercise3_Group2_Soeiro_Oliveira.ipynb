{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands On Exercise 3: Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLbEKL7BLvmh"
   },
   "source": [
    "**Chapter 6 – Decision Trees**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nN3OdD0LLvmk"
   },
   "source": [
    "Due date: 2022-02-14\n",
    "\n",
    "File name convention: For group 42 and memebers Richard Stallman and Linus Torvalds it would be \n",
    "\"03_Decision_Trees_Goup42_Stallman_Torvalds.pdf\".\n",
    "\n",
    "Submission via blackboard (UA) or Google Form (see notion, LPC).\n",
    "\n",
    "Feel free to answer free text questions in text cells using markdown and possibly $\\LaTeX{}$ if you want to.\n",
    "\n",
    "**You don't have to understand every line of code here and it is not intended for you to try to understand every line of code.   \n",
    "Big blocks of code are usually meant to just be clicked through.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdYKH0beLvml"
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/UAPH4582/PH482_582_Sp22/blob/main/Exercises/03_Decision_Trees.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Py2NOeBLvml"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AKxv51qSLvmm"
   },
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "slm-PTBnLvmn"
   },
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will be using the [iris dataset](https://archive.ics.uci.edu/ml/datasets/Iris).\n",
    "Try to understand the features (`X[i]`) and the labels (`y[i]`) from the link above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NHKUSfoPLvmn"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "#Load the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data[:, 2:] # petal length and width\n",
    "y = iris.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vAG_6mzJLvmo",
    "outputId": "23547549-8587-4ee9-e09f-035403f6fbdb"
   },
   "outputs": [],
   "source": [
    "X.shape  # 150 instances, 2 features per instance (petal length and width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "esMJWWLaLvmp",
    "outputId": "f5c5cf4b-7f7e-48e5-b45b-dcc5561ec0dc"
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LqN-n6Z_Lvmq"
   },
   "source": [
    "Now that we have the data we can fit a model to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NR5pE8RNLvmq"
   },
   "source": [
    "# Decision Trees for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "huyiT7KXLvmq"
   },
   "source": [
    "### Task 1\n",
    "\n",
    "Build a simple [decision tree classifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) with `max_depth` of 2 and `random_state` of 40. Fit to the data `X`, `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LtBJvshWLvmr"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzACHvMk2hd6"
   },
   "source": [
    "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓\n",
    "your code goes below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0su6wPoLLvmr"
   },
   "outputs": [],
   "source": [
    "# tree_clf = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sam0EOraLvmr",
    "outputId": "7a7f2b01-e651-4afa-af3f-232e603c4c9b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCHZcxPr2tqY"
   },
   "source": [
    "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above this "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CAPW_1OxLvms"
   },
   "source": [
    "### Visualization of the Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrWXPwvvLvms"
   },
   "source": [
    "**Note** Next step requires the GraphViz executable installed. Since there is a lot of additional work, it is recommended to work through a Colab notebook instead. However, if you'd like to continue working locally, follow the steps below. \n",
    "\n",
    "To intall GraphViz, download it here: https://graphviz.org/download/\n",
    "\n",
    "During the installation, make sure its path was added to the Path environmental variable. For your user, add the path to the bin folder, for the system environmental variable, add the path to the ```dot.exe``` file. \n",
    "```\n",
    "C:\\Program Files (x86)\\Graphviz2.38\\bin\n",
    "C:\\Program Files (x86)\\Graphviz2.38\\bin\\dot.exe\n",
    "``` \n",
    "\n",
    "Then, you can use pip or conda to install the package: ```pip install graphiz``` or ```conda install graphiz```\n",
    "\n",
    "Finally, close your Jupyter notebook, close the command promt executing it and restart both. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440
    },
    "id": "3gziiuAgLvmt",
    "outputId": "039fcfea-5dfe-4d6d-8e4e-b3d4ee635357"
   },
   "outputs": [],
   "source": [
    "from graphviz import Source\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "IMAGES_PATH = os.path.join(\".\", \"images\")\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "export_graphviz(\n",
    "        tree_clf,\n",
    "        out_file=os.path.join(IMAGES_PATH, \"iris_tree.dot\"),\n",
    "        feature_names=iris.feature_names[2:],\n",
    "        class_names=iris.target_names,\n",
    "        rounded=True,\n",
    "        filled=True\n",
    "    )\n",
    "\n",
    "Source.from_file(os.path.join(IMAGES_PATH, \"iris_tree.dot\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "id": "62w-roFsLvmt",
    "outputId": "ff67f978-f714-4e1f-b773-db96c093ad85"
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_decision_boundary(clf, X, y, axes=[0, 7.5, 0, 3], iris=True, legend=False, plot_training=True):\n",
    "    x1s = np.linspace(axes[0], axes[1], 100)\n",
    "    x2s = np.linspace(axes[2], axes[3], 100)\n",
    "    x1, x2 = np.meshgrid(x1s, x2s)\n",
    "    X_new = np.c_[x1.ravel(), x2.ravel()]\n",
    "    y_pred = clf.predict(X_new).reshape(x1.shape)\n",
    "    custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
    "    plt.contourf(x1, x2, y_pred, alpha=0.3, cmap=custom_cmap)\n",
    "    if not iris:\n",
    "        custom_cmap2 = ListedColormap(['#7d7d58','#4c4c7f','#507d50'])\n",
    "        plt.contour(x1, x2, y_pred, cmap=custom_cmap2, alpha=0.8)\n",
    "    if plot_training:\n",
    "        plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"yo\", label=\"Iris setosa\")\n",
    "        plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bs\", label=\"Iris versicolor\")\n",
    "        plt.plot(X[:, 0][y==2], X[:, 1][y==2], \"g^\", label=\"Iris virginica\")\n",
    "        plt.axis(axes)\n",
    "    if iris:\n",
    "        plt.xlabel(\"Petal length\", fontsize=14)\n",
    "        plt.ylabel(\"Petal width\", fontsize=14)\n",
    "    else:\n",
    "        plt.xlabel(r\"$x_1$\", fontsize=18)\n",
    "        plt.ylabel(r\"$x_2$\", fontsize=18, rotation=0)\n",
    "    if legend:\n",
    "        plt.legend(loc=\"lower right\", fontsize=14)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plot_decision_boundary(tree_clf, X, y)\n",
    "plt.plot([2.45, 2.45], [0, 3], \"k-\", linewidth=2)\n",
    "plt.plot([2.45, 7.5], [1.75, 1.75], \"k--\", linewidth=2)\n",
    "plt.plot([4.95, 4.95], [0, 1.75], \"k:\", linewidth=2)\n",
    "plt.plot([4.85, 4.85], [1.75, 3], \"k:\", linewidth=2)\n",
    "plt.text(1.40, 1.0, \"Depth=0\", fontsize=15)\n",
    "plt.text(3.2, 1.80, \"Depth=1\", fontsize=13)\n",
    "plt.text(4.05, 0.5, \"(Depth=2)\", fontsize=11)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GG5_hSo9Lvmu"
   },
   "source": [
    "## Predicting classes and class probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LoFdkAfPLvmu"
   },
   "source": [
    "### Task 2\n",
    "Next, predict the probabilities and the class for the following values: ``` [5, 1.5] ```.\n",
    "\n",
    "You will need the functions `tree_clf.predict_proba()` and `tree_clf.predict()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zjoh3xeA36Rc"
   },
   "source": [
    "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓\n",
    "your code goes below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fGOKuN7zLvmu",
    "outputId": "142ac1cf-f8a4-48ed-d2c9-f01e13e0a10c"
   },
   "outputs": [],
   "source": [
    "# pred_prob = \n",
    "# pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NI9sJ915Lvmu",
    "outputId": "3de303c1-74cf-491a-b508-5bdbebd80c90"
   },
   "outputs": [],
   "source": [
    "# y_pred = \n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9UKK78g38bM"
   },
   "source": [
    "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above this "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Diwf_pKgLvmv"
   },
   "source": [
    "You can also check in the plot above in what class you would put the instance `[5, 1.5]`.\n",
    "In the plot yellow corresponds to class 0 (Iris setosa), blue corresponds to class 1 (Iris versicolor) and green corresponds to class 2 (Iris virginica)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06craaUpLvmv"
   },
   "source": [
    "## Sensitivity to training set details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_T9FESIKLvmv"
   },
   "source": [
    "### Task 3\n",
    "Next, we want to expolore the sensitivity to the training set details. \n",
    "We will train the same decision tree model, but with slightly different training data.\n",
    "\n",
    "\n",
    "**Task 3a**: What does the output below show? \n",
    "\n",
    "Hint: refer to the [dataset description](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html)\n",
    "and think about the slicing of the array below. Which values are selected and which data do they show?\n",
    "It helps to evaluate parts of the expression separately and try to understand them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_b6kbQlWLvmv",
    "outputId": "4a4550bf-0fd4-4d41-aee6-dbe84e4b5f6d"
   },
   "outputs": [],
   "source": [
    "X[(X[:, 1]==X[:, 1][y==1].max()) & (y==1)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXfv9e_SLvmv"
   },
   "source": [
    "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓\n",
    "your code goes below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Y9x_e-tLvmv"
   },
   "source": [
    "Task 3a answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJ8fLtTKLvmw"
   },
   "source": [
    "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above this "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1EatTXtOLvmw"
   },
   "source": [
    "**Task 3b**: Now, what if we select the values that are NOT 1.8. Which data would the dataset represent? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l24q8LbZLvmw"
   },
   "source": [
    "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓\n",
    "your code goes below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mA4_p-1NLvmw"
   },
   "source": [
    "Task 3b answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_we9tatLvmw"
   },
   "source": [
    "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p9Ih_SPJLvmw"
   },
   "outputs": [],
   "source": [
    "not_1_8 = (X[:, 1]!=1.8) | (y==2)\n",
    "X_tweaked = X[not_1_8]\n",
    "y_tweaked = y[not_1_8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2R8FoyfLvmx"
   },
   "source": [
    "**Task 3c**: Fit a new Decision Tree Classifier to these values (`X_tweaked`, `y_tweaked`) with the same initial parameter values ```max_depth = 2``` and ```random_state = 42```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmkWDe7wLvmx"
   },
   "source": [
    "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓\n",
    "your code goes below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vohlqSe7Lvmx",
    "outputId": "9fc5036c-427e-4601-dc97-3bb235543cec"
   },
   "outputs": [],
   "source": [
    "# tree_clf_tweaked = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edgT5nsVLvmx"
   },
   "source": [
    "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above this "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QaL72ABNLvmx"
   },
   "source": [
    "So now we have trained a new decision tree `tree_clf_tweaked` that has slightly different training data (actually only *one* element less).   \n",
    "Let's visualize the new decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "id": "1SXLFWekLvmx",
    "outputId": "9ab84f17-ff31-49e4-e5de-ede3c30a2632"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plot_decision_boundary(tree_clf_tweaked, X_tweaked, y_tweaked, legend=False)\n",
    "plt.plot([0, 7.5], [0.8, 0.8], \"k-\", linewidth=2)\n",
    "plt.plot([0, 7.5], [1.75, 1.75], \"k--\", linewidth=2)\n",
    "plt.text(1.0, 0.9, \"Depth=0\", fontsize=15)\n",
    "plt.text(1.0, 1.80, \"Depth=1\", fontsize=13)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3KDj1inqLvmy"
   },
   "source": [
    "**Task 3d**: Describe how the new decision tree is different from the one before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kscTnPS1Lvmy"
   },
   "source": [
    "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓\n",
    "your code goes below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WyF_v-9Lvmy"
   },
   "source": [
    "Task 3d answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EBN0Ja4NLvmy"
   },
   "source": [
    "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above this "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_taL5yIyLvmy"
   },
   "source": [
    "# Regression Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWCFARlILvmy"
   },
   "source": [
    "In this subsection, we will be working with a regression task. \n",
    "Notice that the dataset below is different. Here we are using a training set generated by a quadratic function with the addition of some random noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U_680ZX4Lvmy"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "m = 200\n",
    "X = np.random.rand(m, 1)\n",
    "y = 4 * (X - 0.5) ** 2\n",
    "y = y + np.random.randn(m, 1) / 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fT4eSc39Lvmy"
   },
   "source": [
    "### Task 4\n",
    "Similar to what you've done above, create a [decision tree regressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) with the same hyperparameters as the classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D0P4Z_ivLvmy"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5IeVa0P6k0E"
   },
   "source": [
    "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your code goes below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nGp1S4tkLvmz"
   },
   "outputs": [],
   "source": [
    "# tree_reg = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OQ736E0QLvmz",
    "outputId": "74ae045e-9d6d-4d20-9c5b-cc5637b2252a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_o9Bq2js73A4"
   },
   "source": [
    "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above this "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tqv5xTc7Lvmz"
   },
   "source": [
    "Below, you'll see the difference in the prediction for an increased value of the ```max_depth``` parameter. What can you say about the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "m6-d4F5PLvmz",
    "outputId": "b08e5fad-1e50-400d-d09a-40d8b94ada7f"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg1 = DecisionTreeRegressor(random_state=42, max_depth=2)\n",
    "tree_reg2 = DecisionTreeRegressor(random_state=42, max_depth=3)\n",
    "tree_reg1.fit(X, y)\n",
    "tree_reg2.fit(X, y)\n",
    "\n",
    "def plot_regression_predictions(tree_reg, X, y, axes=[0, 1, -0.2, 1], ylabel=\"$y$\"):\n",
    "    x1 = np.linspace(axes[0], axes[1], 500).reshape(-1, 1)\n",
    "    y_pred = tree_reg.predict(x1)\n",
    "    plt.axis(axes)\n",
    "    plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "    if ylabel:\n",
    "        plt.ylabel(ylabel, fontsize=18, rotation=0)\n",
    "    plt.plot(X, y, \"b.\")\n",
    "    plt.plot(x1, y_pred, \"r.-\", linewidth=2, label=r\"$\\hat{y}$\")\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)\n",
    "plt.sca(axes[0])\n",
    "plot_regression_predictions(tree_reg1, X, y)\n",
    "for split, style in ((0.1973, \"k-\"), (0.0917, \"k--\"), (0.7718, \"k--\")):\n",
    "    plt.plot([split, split], [-0.2, 1], style, linewidth=2)\n",
    "plt.text(0.21, 0.65, \"Depth=0\", fontsize=15)\n",
    "plt.text(0.01, 0.2, \"Depth=1\", fontsize=13)\n",
    "plt.text(0.65, 0.8, \"Depth=1\", fontsize=13)\n",
    "plt.legend(loc=\"upper center\", fontsize=18)\n",
    "plt.title(\"max_depth=2\", fontsize=14)\n",
    "\n",
    "plt.sca(axes[1])\n",
    "plot_regression_predictions(tree_reg2, X, y, ylabel=None)\n",
    "for split, style in ((0.1973, \"k-\"), (0.0917, \"k--\"), (0.7718, \"k--\")):\n",
    "    plt.plot([split, split], [-0.2, 1], style, linewidth=2)\n",
    "for split in (0.0458, 0.1298, 0.2873, 0.9040):\n",
    "    plt.plot([split, split], [-0.2, 1], \"k:\", linewidth=1)\n",
    "plt.text(0.3, 0.5, \"Depth=2\", fontsize=13)\n",
    "plt.title(\"max_depth=3\", fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3crrk6E0Lvm0"
   },
   "outputs": [],
   "source": [
    "export_graphviz(\n",
    "        tree_reg1,\n",
    "        out_file=os.path.join(IMAGES_PATH, \"regression_tree.dot\"),\n",
    "        feature_names=[\"x1\"],\n",
    "        rounded=True,\n",
    "        filled=True\n",
    "    )\n",
    "Source.from_file(os.path.join(IMAGES_PATH, \"regression_tree.dot\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxasJyRFLvm0"
   },
   "source": [
    "## Restricting the Tree with `min_samples_leaf`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4jVUrTPLvm0"
   },
   "source": [
    "Here we are restricting the tree to `min_samples_leaf=10`. You can read about it in [the documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "u__spHoSLvm0",
    "outputId": "62bc0036-f53d-4d40-9b03-3f99b528b3e1"
   },
   "outputs": [],
   "source": [
    "tree_reg1 = DecisionTreeRegressor(random_state=42)\n",
    "tree_reg2 = DecisionTreeRegressor(random_state=42, min_samples_leaf=10)\n",
    "tree_reg1.fit(X, y)\n",
    "tree_reg2.fit(X, y)\n",
    "\n",
    "x1 = np.linspace(0, 1, 500).reshape(-1, 1)\n",
    "y_pred1 = tree_reg1.predict(x1)\n",
    "y_pred2 = tree_reg2.predict(x1)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)\n",
    "\n",
    "plt.sca(axes[0])\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.plot(x1, y_pred1, \"r.-\", linewidth=2, label=r\"$\\hat{y}$\")\n",
    "plt.axis([0, 1, -0.2, 1.1])\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", fontsize=18, rotation=0)\n",
    "plt.legend(loc=\"upper center\", fontsize=18)\n",
    "plt.title(\"No restrictions\", fontsize=14)\n",
    "\n",
    "plt.sca(axes[1])\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.plot(x1, y_pred2, \"r.-\", linewidth=2, label=r\"$\\hat{y}$\")\n",
    "plt.axis([0, 1, -0.2, 1.1])\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.title(\"min_samples_leaf={}\".format(tree_reg2.min_samples_leaf), fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TfioJ6bhLvm0"
   },
   "source": [
    "### Task 5\n",
    "\n",
    "Discuss the effect of the restrictions on the regression results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3pu8O_PnLvm1"
   },
   "source": [
    "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your code goes below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CwwXiX4cLvm1"
   },
   "source": [
    "Task 5 answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rBE7oVb9Lvm1"
   },
   "source": [
    "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above this "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3IfDqQRLvm1"
   },
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WnVP54rLvm1"
   },
   "source": [
    "In this exercise you will be using the [make_moons](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html) dataset. You can see a plot below. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pDumL4RnLvm1"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=10000, noise=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "RQeS4I_nLvm1",
    "outputId": "d5ce51d5-cc92-469f-833f-c0e102aec22c"
   },
   "outputs": [],
   "source": [
    "cm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"])\n",
    "plt.scatter(X[:,0], X[:,1], c=y, cmap=cm_bright, edgecolors=\"k\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qn5Cxp6lLvm2",
    "outputId": "dfdaaf1b-c430-4766-bdf7-4f4afc197a94"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QLtSoaJXLvm2",
    "outputId": "06d07eff-6a74-4df2-9fe6-e6246cb12abe"
   },
   "outputs": [],
   "source": [
    "tree_moons = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "                       max_features=None, max_leaf_nodes=17,\n",
    "                       min_impurity_decrease=0.0, \n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, \n",
    "                       random_state=42, splitter='best')\n",
    "tree_moons.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uztDNVn4Lvm2",
    "outputId": "90d99500-af2d-4d01-b60a-be47412001db"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred_moons = tree_moons.predict(X_test)\n",
    "accuracy_score(y_test, y_pred_moons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28IASpWkLvm2"
   },
   "source": [
    "The decision tree trained with all data has an accuracy as shown above.\n",
    "Now we will build a forest consisting of trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GF7rD4OdLvm2"
   },
   "source": [
    "We will be building 100 `DecisionTreeClassifier`s.\n",
    "First we do a train-test-split to get training and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JdooBsL9Lvm2"
   },
   "source": [
    "As you can see, the training data has a size of 8000 instances.\n",
    "Let's generate 1000 subsets (mini-sets) of `X_train`, each containing 100 instances selected randomly.\n",
    "Then we will train a separate tree on each of the mini-sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2CHBb3ZHLvm2"
   },
   "source": [
    "## Task 6\n",
    "\n",
    "Grow a forest.\n",
    "You will have to get the following done, the way you implement it is your choice:\n",
    "\n",
    "- Split `X_train` into 1000 subsets, each containing 100 instances selected randomly. You can use sklearn's [ShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html) for this. \n",
    "- Train one [Decision Tree](https://scikit-learn.org/0.17/modules/generated/sklearn.tree.DecisionTreeClassifier.html) on each subset. The hyperparameter values below work well:\n",
    "```python\n",
    "class_weight=None, criterion='gini', max_depth=None,\n",
    "                       max_features=None, max_leaf_nodes=17,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, \n",
    "                       random_state=42, splitter='best'\n",
    "```\n",
    "You might need `from sklearn.base import clone`. To clone the tree 1000 times.\n",
    "- calculate the accuracy on the test data `X_test`, `y_test` for each tree. What is the mean accuracy?\n",
    "- Build a forest: For each test set instance, generate the predictions of the 1,000 Decision Trees, and keep only the most frequent prediction (you can use SciPy's `scipy.stats.mode()` function for this). This gives you _majority-vote predictions_ over the test set. What is the accuracy of your fores? You should get a slightly better accuracy than the one tree trained on all training data.\n",
    "\n",
    "\n",
    "If you struggle with this task for too long, then you can find the solution [here](https://github.com/ageron/handson-ml2/blob/master/06_decision_trees.ipynb) under 8 (bottom of the notebook) or [here](https://github.com/UAPH4582/PH482_582_Sp22/blob/main/Exercises/03_Forest_Solution.ipynb).\n",
    "Try not to copy all of the code, but at least write some of it yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7HMNRC-7Lvm3"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.base import clone\n",
    "from scipy.stats import mode\n",
    "\n",
    "\n",
    "n_trees = 1000\n",
    "n_instances = 100\n",
    "mini_sets = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nsnymzLuLvm2"
   },
   "source": [
    "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your code goes below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L33GBuxILvm4"
   },
   "source": [
    "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above this "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "03_Decision_Trees_Solution.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nav_menu": {
   "height": "309px",
   "width": "468px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
